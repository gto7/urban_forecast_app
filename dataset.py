# -*- coding: utf-8 -*-
"""Untitled26.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1phSRaS8Uj3phc_4x6hLadTSjpiz_PBRu
"""


import os
import pandas as pd
import geopandas as gpd





class GeospatialLoader:
    """Classe pour charger et transformer des données géospatiales."""

    def __init__(self, base_path: str):
        """
        Initialise le chargeur avec un chemin de base pour les données.
        """
        self.base_path = base_path

    def load_file_footprint(self, sub_path: str) -> gpd.GeoDataFrame:
        """
        Charge et compile les polygones des différentes zones à partir de fichiers de footprint.
        """
        path_data = os.path.join(self.base_path, sub_path)
        list_files = [os.path.join(path_data, i) for i in os.listdir(path_data) if "empreinte_urbaine" in i and i.endswith(".shp")]
        data_zone = pd.DataFrame()
        id_index = [i.split("_")[2].split('.')[0] for i in list_files]

        for link in list_files:
            zone = gpd.read_file(link)
            data_zone = pd.concat([data_zone, zone])

        data_zone["year"] = id_index
        data_zone.drop(columns="id", axis=1, inplace=True)
        data_zone.reset_index(drop=True, inplace=True)
      #  data_zone = data_zone.explode()
        data_zone = data_zone.to_crs("EPSG:4326")
        data_zone['centroid'] = data_zone.geometry.centroid
        data_zone['area (hectare)'] = data_zone.geometry.area / 10000
        return data_zone

    def load_poly_limit(self, filename: str) -> gpd.GeoDataFrame:
        """
        Charge et reprojette un fichier géospatial au format EPSG:4326.
        """
        path_file = os.path.join(self.base_path, filename)
        limit_geom = gpd.read_file(path_file)
        return limit_geom.to_crs("EPSG:4326")

    def load_ppr(self, filename: str, limit_geom: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
        """
        Charge et reprojette un fichier PPR, avec un filtre géométrique.
        """
        path_file = os.path.join(self.base_path, filename)
        ppr = gpd.read_file(path_file, mask=limit_geom)

        #filtrage des INTERDICTIONS PPR 

        ppr = ppr[ppr['degre'] == 'INTERDICTION']
        return ppr.to_crs("EPSG:4326")

    def load_plu(self, filename: str, limit_geom: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
        """
        Charge et reprojette un fichier PLU avec un filtre géométrique.
        """
        path_file = os.path.join(self.base_path, filename)
        plu = gpd.read_file(path_file, mask=limit_geom)
        return plu.to_crs("EPSG:4326")

    def load_carreaux(self, filename: str, limit_geom: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
        """
        Charge et reprojette les carreaux géométriques avec un filtre.
        """
        path_file = os.path.join(self.base_path, filename)
        carreaux = gpd.read_file(path_file, mask=limit_geom)[['Idcar_200m', "Ind", "geometry"]]
        return carreaux.to_crs("EPSG:4326")


class DataProcessor:
    """Classe pour le traitement et la manipulation des données géospatiales."""

    @staticmethod
    def reduce_plu_by_ppr(plu: gpd.GeoDataFrame, ppr: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
        """
        Réduit les polygones de `plu` en enlevant uniquement les parties qui se chevauchent avec `ppr`.
        """
        ppr_union = ppr.unary_union
        plu["geometry"] = plu.geometry.apply(lambda x: x.difference(ppr_union))
        plu = plu[~plu.geometry.is_empty]
        return plu


class Preprocessor:
    """Classe pour prétraiter les données géospatiales pour analyse."""

    def __init__(self, base_path: str):
        self.loader = GeospatialLoader(base_path)

    def preprocessing_zone(self) -> gpd.GeoDataFrame:
      """
      Effectue le prétraitement des données géospatiales pour les zones.
      """
      # Charger les limites géographiques
      lim = self.loader.load_poly_limit("limites_commune.shp")

      urbain = self.loader.load_file_footprint(self.loader.base_path)

      # Charger les couches PPR et PLU
      ppr = self.loader.load_ppr("ppr_approuve/ppr_approuvePolygon.shp", limit_geom=lim)
      plu = self.loader.load_plu("PLU/plu.shp", limit_geom=lim)

      # Charger les carreaux géométriques
      car_df = self.loader.load_carreaux(
          os.path.join(base_path, "Filosofi2017_carreaux_200m_shp/Filosofi2017_carreaux_200m_reun.shp"), 
          limit_geom=lim
      )

      # Réduire les polygones du PLU en fonction du PPR
      reduced_plu = DataProcessor.reduce_plu_by_ppr(plu, ppr)

      print(reduced_plu.columns)

      # Effectuer une jointure spatiale (right join) pour éviter les doublons
      data = reduced_plu.sjoin(car_df, how="right", predicate="intersects")

      # Assigner un ID unique à chaque enregistrement
      data = data.reset_index()  # Réinitialiser l'index pour avoir des IDs uniques
      data["unique_id"] = data.index

      # Vérifier et supprimer les doublons si nécessaires
      data = data.drop_duplicates(subset=[ "Idcar_200m"])
      data['Ind'] = data['Ind'].astype(int)
      # Optionnel : Ajouter une agrégation pour la population (exemple)
      result = data.groupby('ogc_fid', as_index=False)['Ind'].sum()
      
      result['ogc_fid'] = result['ogc_fid'].astype(int)

      result = result.merge(reduced_plu[['ogc_fid' , 'libelle' , 'typezone' , "datappro",	"datmodif" , 	"datefinval" , "geometry"]] , on= "ogc_fid" , how = 'left')

      result = gpd.GeoDataFrame(result)

      result['intersection urbain'] = result['geometry'].intersection(urbain[urbain['year'] =="2020"]['geometry'].reset_idnex(drop = True).loc[0])
      result = result.to_crs(epsg=2154)

      result['area (hectare)'] = result.geometry.area / 10000   


      return result 




